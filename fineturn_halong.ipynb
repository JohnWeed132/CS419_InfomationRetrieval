{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T17:55:03.862731Z",
     "iopub.status.busy": "2025-01-27T17:55:03.862427Z",
     "iopub.status.idle": "2025-01-27T17:55:11.696936Z",
     "shell.execute_reply": "2025-01-27T17:55:11.695809Z",
     "shell.execute_reply.started": "2025-01-27T17:55:03.862699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.47.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers datasets accelerate\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:56:10.814857Z",
     "iopub.status.busy": "2025-01-27T17:56:10.814550Z",
     "iopub.status.idle": "2025-01-27T17:56:11.049546Z",
     "shell.execute_reply": "2025-01-27T17:56:11.048901Z",
     "shell.execute_reply.started": "2025-01-27T17:56:10.814832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from datasets import load_dataset, Dataset\n",
    "import gdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:56:13.131608Z",
     "iopub.status.busy": "2025-01-27T17:56:13.130967Z",
     "iopub.status.idle": "2025-01-27T17:56:21.567196Z",
     "shell.execute_reply": "2025-01-27T17:56:21.566496Z",
     "shell.execute_reply.started": "2025-01-27T17:56:13.131579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gdown.download('','/kaggle/working/corpus.csv',fuzzy=True)\n",
    "gdown.download('','/kaggle/working/train.csv',fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:57:01.341754Z",
     "iopub.status.busy": "2025-01-27T17:57:01.341463Z",
     "iopub.status.idle": "2025-01-27T17:57:01.691730Z",
     "shell.execute_reply": "2025-01-27T17:57:01.691071Z",
     "shell.execute_reply.started": "2025-01-27T17:57:01.341734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cp = pd.read_csv('/kaggle/working/corpus.csv')\n",
    "cp['content_id'] = cp['document'] + ' ' + cp['article']\n",
    "train = pd.read_csv('/kaggle/working/train.csv')\n",
    "train['content_id'] = train['document'] + ' ' + train['article']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:57:18.830648Z",
     "iopub.status.busy": "2025-01-27T17:57:18.830333Z",
     "iopub.status.idle": "2025-01-27T17:57:18.849670Z",
     "shell.execute_reply": "2025-01-27T17:57:18.848428Z",
     "shell.execute_reply.started": "2025-01-27T17:57:18.830620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(zip(cp[\"content_id\"], cp[\"context\"]))  # Our corpus (cid => document)\n",
    "queries = dict(zip(train[\"question\"], train[\"question\"]))  # Our queries (qid => question)\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for qid, corpus_ids in zip(train[\"question\"], train[\"content_id\"]):\n",
    "    qid = str(qid)\n",
    "    corpus_ids = str(corpus_ids)\n",
    "    if qid not in relevant_docs:\n",
    "        relevant_docs[qid] = set()\n",
    "    relevant_docs[qid].add(corpus_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:08.382590Z",
     "iopub.status.busy": "2025-01-27T17:59:08.382294Z",
     "iopub.status.idle": "2025-01-27T17:59:10.562825Z",
     "shell.execute_reply": "2025-01-27T17:59:10.562107Z",
     "shell.execute_reply.started": "2025-01-27T17:59:08.382567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "model = SentenceTransformer(\"hiieu/halong_embedding\")\n",
    "matryoshka_dimensions = [768, 512] # Important: large to small\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:10.564273Z",
     "iopub.status.busy": "2025-01-27T17:59:10.563925Z",
     "iopub.status.idle": "2025-01-27T17:59:17.139599Z",
     "shell.execute_reply": "2025-01-27T17:59:17.138835Z",
     "shell.execute_reply.started": "2025-01-27T17:59:10.564243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_accuracy@1 0.574\n",
      "dim_768_cosine_accuracy@3 0.75\n",
      "dim_768_cosine_accuracy@5 0.818\n",
      "dim_768_cosine_accuracy@10 0.86\n",
      "dim_768_cosine_precision@1 0.574\n",
      "dim_768_cosine_precision@3 0.24999999999999997\n",
      "dim_768_cosine_precision@5 0.1636\n",
      "dim_768_cosine_precision@10 0.086\n",
      "dim_768_cosine_recall@1 0.574\n",
      "dim_768_cosine_recall@3 0.75\n",
      "dim_768_cosine_recall@5 0.818\n",
      "dim_768_cosine_recall@10 0.86\n",
      "dim_768_cosine_ndcg@10 0.7206348883663962\n",
      "dim_768_cosine_mrr@10 0.6754904761904761\n",
      "dim_768_cosine_map@100 0.6812806681618039\n",
      "dim_512_cosine_accuracy@1 0.568\n",
      "dim_512_cosine_accuracy@3 0.746\n",
      "dim_512_cosine_accuracy@5 0.804\n",
      "dim_512_cosine_accuracy@10 0.86\n",
      "dim_512_cosine_precision@1 0.568\n",
      "dim_512_cosine_precision@3 0.24866666666666662\n",
      "dim_512_cosine_precision@5 0.1608\n",
      "dim_512_cosine_precision@10 0.086\n",
      "dim_512_cosine_recall@1 0.568\n",
      "dim_512_cosine_recall@3 0.746\n",
      "dim_512_cosine_recall@5 0.804\n",
      "dim_512_cosine_recall@10 0.86\n",
      "dim_512_cosine_ndcg@10 0.7154724096290774\n",
      "dim_512_cosine_mrr@10 0.6689261904761903\n",
      "dim_512_cosine_map@100 0.6745405337582239\n",
      "sequential_score 0.7154724096290774\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    "for k,v in results.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:17.141422Z",
     "iopub.status.busy": "2025-01-27T17:59:17.140925Z",
     "iopub.status.idle": "2025-01-27T17:59:17.158952Z",
     "shell.execute_reply": "2025-01-27T17:59:17.158051Z",
     "shell.execute_reply.started": "2025-01-27T17:59:17.141382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['anchor', 'positive'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def prepare_training_dataset(queries, corpus, relevant_docs):\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    for query_id, docs in relevant_docs.items():\n",
    "        for doc_id in docs:\n",
    "          anchors.append(queries[query_id])\n",
    "          positives.append(corpus[doc_id] )\n",
    "    df = {\n",
    "        \"anchor\": anchors,\n",
    "        \"positive\": positives\n",
    "    }\n",
    "\n",
    "    return Dataset.from_dict(df)\n",
    "\n",
    "pairs = prepare_training_dataset(queries, corpus, relevant_docs)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:24.122610Z",
     "iopub.status.busy": "2025-01-27T17:59:24.122290Z",
     "iopub.status.idle": "2025-01-27T17:59:24.130203Z",
     "shell.execute_reply": "2025-01-27T17:59:24.129309Z",
     "shell.execute_reply.started": "2025-01-27T17:59:24.122583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'Sinh viên dự bị không trở thành sinh viên chính thức bao nhiêu học kỳ sẽ bị loại khỏi CTTN?',\n",
       " 'positive': 'Điều  9.\\tTuyển bổ sung và loại ra khỏi chương trình, xét chính thức và dự bị\\nĐối tượng tham gia CTTN là những sinh viên có năng lực xuất sắc, do đó, sau mỗi học kỳ BĐH quyết định việc loại sinh viên khỏi lớp tài năng, tuyển bổ sung sinh viên từ chương trình chuẩn vào lớp tài năng, xét chuyển đổi sinh viên chính thức và dự bị.\\nĐầu mỗi học kỳ, Khoa xét và đề nghị lên BĐH các danh sách sinh viên tuyển bổ sung, bị loại ra khỏi các lớp CTTN hoặc danh sách sinh viên chính thức và dự bị theo các tiêu chuẩn như sau:\\n1.\\tLoại khỏi chương trình\\nTại thời điểm xem xét, sinh viên rơi vào một trong các trường hợp sau:\\n-\\tChưa tốt nghiệp khi đã quá thời gian thiết kế của khóa học và không có lý do đặc biệt.\\n-\\tKhông đăng ký học đầy đủ các môn học CTTN bắt buộc trong học kỳ.\\n-\\tĐTBTL nhỏ hơn 6,5 – tính tương ứng sau học kỳ 1 và sau học kỳ hè (kết quả học tập của học kỳ hè sẽ được tính chung vào kết quả học tập học kỳ 2 của năm học tương ứng).\\n-\\tSố tín chỉ tích lũy (STCTL) so với tiến độ CTĐT nhỏ hơn 80% nếu đang học năm 1, 2 hoặc nhỏ hơn 90% nếu đang học các năm trên.\\n-\\tĐTBHK nhỏ hơn 6,5 hoặc hai học kỳ liên tiếp (tính cả học kỳ trước khi tuyển vào lớp CTTN) nhỏ hơn 7,0 – chỉ tính các học kỳ chính.\\n-\\tĐiểm rèn luyện dưới mức KHÁ – tính theo qui định hiện hành.\\n-\\tNằm trong danh sách sinh viên dự bị 02 học kỳ liên tiếp.\\nCác sinh viên bị loại ra khỏi chương trình trong 3 học kỳ đầu tiên của khóa học sẽ được trở về ngành/chuyên ngành gốc theo kết quả tuyển sinh, từ học kỳ thứ 4 trở đi thì sinh viên được chuyển sang lớp chương trình chuẩn cùng ngành/chuyên ngành với lớp CTTN đang học. \\nSinh viên bị loại ra khỏi chương trình không được tham gia dự tuyển bổ sung lại vào chương trình.\\n2.\\tSinh viên xin ra khỏi chương trình\\nSinh viên có yêu cầu cá nhân được phép làm đơn xin ra khỏi chương trình và trở về lớp đào tạo theo chương trình chuẩn phù hợp (tương tự với sinh viên bị loại khỏi chương trình). Nếu sinh viên xin ra khỏi CTTN phải có trách nhiệm hoàn trả lại toàn bộ số tiền học bổng đã nhận theo điều 13 của quy định này.\\n3.\\tTuyển bổ sung sinh viên từ chương trình chuẩn\\nCăn cứ vào chỉ tiêu của từng khóa và số sinh viên bị loại, nếu số sinh viên còn lại của một lớp CTTN ít hơn chỉ tiêu thì Khoa được phép tiến hành tuyển bổ sung.\\nSinh viên vừa được tuyển bổ sung là sinh viên dự bị của lớp tài năng sao cho số lượng sinh viên dự bị không quá 20% tổng số lượng sinh viên của lớp tài năng, trong trường hợp tổng số sinh viên của lớp tài năng chưa đạt 2/3 chỉ tiêu thì được quyền tuyển bổ sung sinh viên dự bị vượt hơn 20% tổng số lượng sinh viên nhưng không được vượt quá chỉ tiêu\\nViệc tuyển bổ sung được thực hiện lần cuối cho học kỳ thứ 4 (xét theo kết quả học kỳ thứ 3). \\nđiều kiện để sinh viên được tham gia dự tuyển bổ sung:\\n-\\tSinh viên chương trình chuẩn đang theo học cùng khóa, cùng ngành với lớp CTTN tương ứng. Trường hợp cần thiết Khoa có thể thông báo tuyển cả các sinh viên một số ngành/chuyên ngành khác - cùng khóa nếu ngành này chưa có sự khác biệt đáng kể về chương trình đào tạo so với ngành đang đào tạo CTTN (số tín chỉ khác biệt < 10%).\\n-\\tCó điểm rèn luyện đạt từ loại Khá trở lên, có nguyện vọng theo học lớp CTTN.\\n-\\tCó STCTL theo tiến độ CTĐT đạt trên 90%.\\n-\\tĐTBHK gần nhất và ĐTBTL tại thời điểm xét tuyển đều từ 7,5 trở lên.\\n-\\tĐiểm tổng kết các môn học cốt lõi (nếu có) đều đạt từ 7,5 trở lên.\\n-\\tĐạt các tiêu chuẩn bổ sung khác do khoa quy định cụ thể.\\n4.\\tChuyển đổi sinh viên chính thức và dự bị\\nSau mỗi học kỳ chính, BĐH và Khoa sẽ căn cứ vào kết quả học tập của toàn bộ sinh viên lớp tài năng để xét lại danh sách sinh viên chính thức và dự bị và trình BGH phê duyệt\\nSinh viên chính thức phải có ĐTBTL >= 7,5 và có STCTL theo tiến độ CTĐT đạt trên 90%.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:29.801520Z",
     "iopub.status.busy": "2025-01-27T17:59:29.801203Z",
     "iopub.status.idle": "2025-01-27T17:59:29.805628Z",
     "shell.execute_reply": "2025-01-27T17:59:29.804866Z",
     "shell.execute_reply.started": "2025-01-27T17:59:29.801492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "matryoshka_dimensions = [768, 512]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:35.733327Z",
     "iopub.status.busy": "2025-01-27T17:59:35.733002Z",
     "iopub.status.idle": "2025-01-27T17:59:35.764670Z",
     "shell.execute_reply": "2025-01-27T17:59:35.763808Z",
     "shell.execute_reply.started": "2025-01-27T17:59:35.733298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"sample\", # output directory and hugging face model ID\n",
    "    num_train_epochs=10,                         # number of epochs\n",
    "    per_device_train_batch_size=8,             # train batch size\n",
    "    gradient_accumulation_steps=4,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=4,              # evaluation batch size\n",
    "    #gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    #tf32=True,                                  # use tf32 precision\n",
    "    bf16=True,                                  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"steps\",                      # evaluate after each epoch\n",
    "    #save_strategy=\"epoch\",                      # save after each epoch\n",
    "    save_steps = 500,\n",
    "    logging_steps=10,                           # log every 10 steps\n",
    "    save_total_limit=3,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_768_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    "     report_to = \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:47.697525Z",
     "iopub.status.busy": "2025-01-27T17:59:47.697224Z",
     "iopub.status.idle": "2025-01-27T17:59:48.167724Z",
     "shell.execute_reply": "2025-01-27T17:59:48.167012Z",
     "shell.execute_reply.started": "2025-01-27T17:59:47.697502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=pairs,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T17:59:53.902565Z",
     "iopub.status.busy": "2025-01-27T17:59:53.902273Z",
     "iopub.status.idle": "2025-01-27T18:01:04.051621Z",
     "shell.execute_reply": "2025-01-27T18:01:04.050571Z",
     "shell.execute_reply.started": "2025-01-27T17:59:53.902543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.645200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.274667</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.773902</td>\n",
       "      <td>0.726056</td>\n",
       "      <td>0.729610</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.772289</td>\n",
       "      <td>0.722507</td>\n",
       "      <td>0.725676</td>\n",
       "      <td>0.772289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at sample/checkpoint-10/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# save the best model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:01:04.053255Z",
     "iopub.status.busy": "2025-01-27T18:01:04.052921Z",
     "iopub.status.idle": "2025-01-27T18:01:11.766452Z",
     "shell.execute_reply": "2025-01-27T18:01:11.765313Z",
     "shell.execute_reply.started": "2025-01-27T18:01:04.053222Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_accuracy@1 0.618\n",
      "dim_768_cosine_accuracy@3 0.828\n",
      "dim_768_cosine_accuracy@5 0.878\n",
      "dim_768_cosine_accuracy@10 0.922\n",
      "dim_768_cosine_precision@1 0.618\n",
      "dim_768_cosine_precision@3 0.276\n",
      "dim_768_cosine_precision@5 0.1756\n",
      "dim_768_cosine_precision@10 0.09219999999999999\n",
      "dim_768_cosine_recall@1 0.618\n",
      "dim_768_cosine_recall@3 0.828\n",
      "dim_768_cosine_recall@5 0.878\n",
      "dim_768_cosine_recall@10 0.922\n",
      "dim_768_cosine_ndcg@10 0.779638998514592\n",
      "dim_768_cosine_mrr@10 0.732915079365079\n",
      "dim_768_cosine_map@100 0.7366734442306533\n",
      "dim_512_cosine_accuracy@1 0.61\n",
      "dim_512_cosine_accuracy@3 0.822\n",
      "dim_512_cosine_accuracy@5 0.876\n",
      "dim_512_cosine_accuracy@10 0.93\n",
      "dim_512_cosine_precision@1 0.61\n",
      "dim_512_cosine_precision@3 0.274\n",
      "dim_512_cosine_precision@5 0.1752\n",
      "dim_512_cosine_precision@10 0.093\n",
      "dim_512_cosine_recall@1 0.61\n",
      "dim_512_cosine_recall@3 0.822\n",
      "dim_512_cosine_recall@5 0.876\n",
      "dim_512_cosine_recall@10 0.93\n",
      "dim_512_cosine_ndcg@10 0.776701905339929\n",
      "dim_512_cosine_mrr@10 0.726838095238095\n",
      "dim_512_cosine_map@100 0.7299640603619946\n",
      "sequential_score 0.776701905339929\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    "\n",
    "for k,v in results.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:01:11.767985Z",
     "iopub.status.busy": "2025-01-27T18:01:11.767677Z",
     "iopub.status.idle": "2025-01-27T18:01:11.950551Z",
     "shell.execute_reply": "2025-01-27T18:01:11.949851Z",
     "shell.execute_reply.started": "2025-01-27T18:01:11.767960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\", add_to_git_credential=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T18:01:58.278734Z",
     "iopub.status.busy": "2025-01-27T18:01:58.278445Z",
     "iopub.status.idle": "2025-01-27T18:02:34.763902Z",
     "shell.execute_reply": "2025-01-27T18:02:34.763123Z",
     "shell.execute_reply.started": "2025-01-27T18:01:58.278713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d72292be1394ae190361a8869149128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9a8c59c0bc4924a3d14ce4e728e18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5ebb13af544dffa345865882df327c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/johnweak132/test_hehe/commit/fa67d082562068f56016181f49591cfe44c2c5b0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push model to hub\n",
    "trainer.model.push_to_hub(\"improve_halong\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
